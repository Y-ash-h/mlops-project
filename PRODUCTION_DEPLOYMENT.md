# Production Deployment Guide

## âœ… Completed Setup

All production components are now deployed:

### 1. **Slack Alerting** ðŸ””
- Location: `mlops-pipeline/src/alerts/slack_notifier.py`
- Webhook configured in `docker-compose.yml`
- Integrated into DAG for:
  - Validation failures
  - Drift detection
  - Model promotion success/blocked

### 2. **Model Cards** ðŸ“„
- Location: `mlops-pipeline/src/model_card/generate_model_card.py`
- Auto-generates HTML with:
  - MLflow run metrics & parameters
  - Artifact listings
  - SHAP visualizations (when available)
- Runs automatically after promotion

### 3. **Model Serving API** ðŸš€
- Service: `model-serving` on port 8000
- Endpoints:
  - `GET /health` - Health check
  - `POST /predict` - Inference
- Loads models from MLflow Production stage

---

## ðŸŽ¯ Current Services

```bash
# Check all services are running
docker compose ps

# Expected services:
# - airflow:       http://localhost:8099  (admin/admin)
# - mlflow:        http://localhost:5050
# - minio:         http://localhost:9000  (minio/minio123)
# - model-serving: http://localhost:8000
# - postgres:      localhost:5432
# - redis:         localhost:6379
```

---

## ðŸ“‹ Next Steps

### Step 1: Run the Pipeline

1. **Access Airflow UI:**
   ```
   http://localhost:8099
   Username: admin
   Password: admin
   ```

2. **Trigger the DAG:**
   - Find `mlops_full_pipeline`
   - Click "Play" button to trigger
   - Monitor task progress

3. **Pipeline Flow:**
   ```
   Detect Data Type
   â†“
   Ingest Data
   â†“
   Validate Data (â†’ Slack alert on failure)
   â†“
   Preprocess Data
   â†“
   Train Model
   â†“
   Monitor Data Drift
   â†“
   Drift Alert Check (â†’ Slack notification)
   â†“
   Check Explainability (branch: tabular vs non-tabular)
   â†“
   Explain Model / Skip Explain
   â†“
   Promote Model (â†’ Slack alert: success/blocked)
   â†“
   Generate Model Card
   ```

### Step 2: View Results

**Model Card:**
```bash
# After pipeline runs successfully
open mlops-pipeline/data/model_card.html
# OR
cat mlops-pipeline/data/model_card.html
```

**Drift Report:**
```bash
open mlops-pipeline/data/monitoring/drift_report.html
```

**Slack Notifications:**
Check your Slack channel for alerts at each critical stage.

### Step 3: Test Model Serving

Once a model is promoted to Production:

```bash
# Health check
curl http://localhost:8000/health

# Sample prediction (adjust features based on your data)
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "instances": [
      {"feature1": 1.0, "feature2": 2.0, "feature3": 3.0}
    ]
  }'
```

**Expected response:**
```json
{
  "predictions": [0.8234],
  "model_name": "tabular_model",
  "model_stage": "Production"
}
```

---

## ðŸ”§ Configuration

### Environment Variables (docker-compose.yml)

**Airflow Service:**
```yaml
environment:
  - MLFLOW_TRACKING_URI=http://mlflow:5000
  - MLFLOW_EXPERIMENT_NAME=demo_experiment
  - LABEL_COLUMN=target
  - MODEL_REGISTRY_NAME=tabular_model
  - SLACK_WEBHOOK=${SLACK_WEBHOOK:-}  # Set in host environment
```

**Model Serving:**
```yaml
environment:
  - MODEL_NAME=tabular_model
  - MODEL_STAGE=Production
  - MLFLOW_TRACKING_URI=http://mlflow:5000
```

### Update Slack Webhook

```bash
# In your terminal
export SLACK_WEBHOOK="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

# Restart Airflow to pick up new env var
docker compose restart airflow
```

---

## ðŸ“Š Monitoring & Logs

### View Service Logs

```bash
# Airflow logs
docker compose logs -f airflow

# Model serving logs
docker compose logs -f model-serving

# MLflow logs
docker compose logs -f mlflow
```

### Access MLflow UI

```
http://localhost:5050
```

- View experiments
- Compare runs
- Inspect model registry
- Download artifacts

---

## ðŸ› Troubleshooting

### Model Serving Returns 404

**Problem:** No model in Production stage
**Solution:**
1. Run the pipeline to train and promote a model
2. Check MLflow UI â†’ Models â†’ `tabular_model`
3. Ensure a version is in "Production" stage

### Slack Alerts Not Working

**Problem:** Webhook not configured or invalid
**Solution:**
```bash
# Verify webhook is set
docker exec mlops_project_clean-airflow-1 env | grep SLACK

# If missing, set it and restart
export SLACK_WEBHOOK="your-webhook-url"
docker compose restart airflow
```

### Model Card Not Generated

**Problem:** No runs found or generation failed
**Solution:**
1. Check Airflow logs for errors
2. Verify MLflow has runs: http://localhost:5050
3. Check task logs in Airflow UI

### Drift Monitoring Fails

**Problem:** Missing train.csv or validation.csv
**Solution:**
```bash
# Check data files exist
docker exec mlops_project_clean-airflow-1 ls -la /opt/airflow/mlops-pipeline/data/

# Verify preprocessing created these files
```

---

## ðŸš€ Production Enhancements

### 1. Intelligent Promotion Logic

Currently, promotion is basic. Enhance with:

```python
def promote(**kwargs):
    # Check metrics threshold
    if latest_accuracy > 0.85 and drift_score < 0.2:
        promote_to_production()
        alert_promotion_success(...)
    else:
        alert_promotion_blocked(...)
```

### 2. A/B Testing Setup

Add shadow deployment:
- Run both Production and Staging models
- Compare predictions
- Gradually shift traffic

### 3. Real-time Monitoring

Set up periodic drift checks:
- Schedule monitoring DAG daily
- Alert on significant drift
- Auto-retrain if needed

### 4. Model Versioning

Enhance model card with:
- Comparison to previous version
- Performance delta
- Deployment history

---

## ðŸ“ API Documentation

### Prediction Endpoint

**POST** `/predict`

**Request:**
```json
{
  "instances": [
    {"feature1": val1, "feature2": val2, ...},
    {"feature1": val3, "feature2": val4, ...}
  ]
}
```

**Response:**
```json
{
  "predictions": [0.82, 0.65],
  "model_name": "tabular_model",
  "model_stage": "Production"
}
```

**Status Codes:**
- 200: Success
- 500: Model loading or prediction error

---

## âœ¨ Summary

Your MLOps pipeline is production-ready with:

âœ… Automated data ingestion & validation  
âœ… Preprocessing for tabular/image/text data  
âœ… Model training with hyperparameter tracking  
âœ… Data drift monitoring with Evidently  
âœ… SHAP explainability for tabular models  
âœ… Intelligent model promotion to MLflow registry  
âœ… Slack alerts for all critical events  
âœ… Auto-generated HTML model cards  
âœ… FastAPI serving with MLflow integration  

**Everything is containerized and orchestrated via Docker Compose!**
